{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d010e1-28db-4ceb-b51a-0a1cc3e48e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import nn\n",
    "# from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242bf7ad-20d3-4dab-b328-333bd64b69dd",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d621f7-5fca-4b31-80f8-26aadcb061c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch import nn\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenized input\n",
    "text = \"Who was Jim Henson ? Jim Henson was a puppeteer\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
    "masked_index = 6\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "assert tokenized_text == ['who', 'was', 'jim', 'henson', '?', 'jim', '[MASK]', 'was', 'a', 'puppet', '##eer']\n",
    "\n",
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8454a427-00ff-4732-bc59-6ef19c6b5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# Predict all tokens\n",
    "predictions = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "# confirm we were able to predict 'henson'\n",
    "predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "assert predicted_token == 'henson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78601b29-39b3-43f7-9447-34a0431c28ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a76a015-1eb3-4700-a3cb-dfd876158751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertOnlyMLMHead(\n",
       "  (predictions): BertLMPredictionHead(\n",
       "    (transform): BertPredictionHeadTransform(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "    )\n",
       "    (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e4b1c92-927f-4e34-9778-efc134f2f78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.9482, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 30522])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 30522\n",
    "tokens = torch.randint(0, vocab_size, (2, 8))\n",
    "segments = torch.tensor([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]])\n",
    "encoded_X = model(input_ids=tokens, token_type_ids=segments, masked_lm_labels=torch.randint(0, 1, (2, 8)))\n",
    "print(encoded_X)\n",
    "encoded_X = model(input_ids=tokens, token_type_ids=segments)\n",
    "encoded_X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9defdef-9cc9-4450-ada5-d5d6c73572cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17448, 17381, 25836, 17989, 29736, 24292,  3180, 25951],\n",
       "        [ 3730, 29404, 10609,  4483, 25146, 13973,  3167, 29150]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa0464d-9adf-4ac7-89cd-7cc68f32e36d",
   "metadata": {},
   "source": [
    "## Changing head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00debe03-aabc-4e2d-9a46-cef8a458441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskLM(nn.Module):\n",
    "    \"\"\"The masked language model task of BERT.\"\"\"\n",
    "    def __init__(self, num_hiddens, **kwargs):\n",
    "        super(MaskLM, self).__init__(**kwargs)\n",
    "        self.mlp = nn.Sequential(nn.Linear(num_hiddens, num_hiddens),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.LayerNorm(num_hiddens),\n",
    "                                 nn.Linear(num_hiddens, 1),\n",
    "                                 nn.Sigmoid())\n",
    "\n",
    "    def forward(self, X):\n",
    "        mlm_Y_hat = self.mlp(X)\n",
    "        return mlm_Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ba157a1-61db-4beb-a7b8-79a3689d8900",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cls = MaskLM(768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca0b7255-e25d-4212-bf47-35be1b4a7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.randint(0, vocab_size, (2, 8))\n",
    "segments = torch.tensor([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]])\n",
    "mlm_positions = torch.tensor([[0,0,0,1,0,0,0,1], [0,1,0,0,1,0,0,1]], dtype=torch.float32)\n",
    "mlm_Y_hat = model(input_ids=tokens, token_type_ids=segments) #masked_lm_labels=mlm_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9be3ef3c-d74f-4127-88bb-fc32fb8fe14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 1]), torch.Size([2, 8]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_Y_hat.shape, mlm_positions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23215715-4f19-4e7b-832c-114f253673a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_positions.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "437e261f-d20e-4b88-909a-03bebc8f5adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_batch_loss_bert(net, loss, vocab_size, tokens_X,\n",
    "                         segments_X,\n",
    "                         masked_lm_labels):\n",
    "    # Forward pass\n",
    "    mlm_Y_hat = net(input_ids=tokens_X, token_type_ids=segments_X)\n",
    "    # loss_fct = CrossEntropyLoss(ignore_index=-1)\n",
    "    masked_lm_loss = loss(mlm_Y_hat.view(-1), masked_lm_labels.view(-1))\n",
    "\n",
    "    return masked_lm_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f38110b-cb37-4ab7-96b6-5bd0597640b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.8079, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_batch_loss_bert(model, CrossEntropyLoss(ignore_index=-1), vocab_size, tokens, segments, mlm_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b9573c-682d-4762-92e5-085acdffda8d",
   "metadata": {},
   "source": [
    "# Training loop TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dd3831e-fddc-49f0-9061-563aa1b64497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bert(train_iter, net, loss, vocab_size, devices, num_steps):\n",
    "    net(*next(iter(train_iter))[:4])\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    trainer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "    step, timer = 0, d2l.Timer()\n",
    "    animator = d2l.Animator(xlabel='step', ylabel='loss',\n",
    "                            xlim=[1, num_steps], legend=['mlm', 'nsp'])\n",
    "    # Sum of masked language modeling losses, sum of next sentence prediction\n",
    "    # losses, no. of sentence pairs, count\n",
    "    metric = d2l.Accumulator(4)\n",
    "    num_steps_reached = False\n",
    "    while step < num_steps and not num_steps_reached:\n",
    "        for tokens_X, segments_X, valid_lens_x, pred_positions_X,\\\n",
    "            mlm_weights_X, mlm_Y, nsp_y in train_iter:\n",
    "            tokens_X = tokens_X.to(devices[0])\n",
    "            segments_X = segments_X.to(devices[0])\n",
    "            valid_lens_x = valid_lens_x.to(devices[0])\n",
    "            pred_positions_X = pred_positions_X.to(devices[0])\n",
    "            mlm_weights_X = mlm_weights_X.to(devices[0])\n",
    "            mlm_Y, nsp_y = mlm_Y.to(devices[0]), nsp_y.to(devices[0])\n",
    "            trainer.zero_grad()\n",
    "            timer.start()\n",
    "            mlm_l, nsp_l, l = _get_batch_loss_bert(\n",
    "                net, loss, vocab_size, tokens_X, segments_X, valid_lens_x,\n",
    "                pred_positions_X, mlm_weights_X, mlm_Y, nsp_y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            metric.add(mlm_l, nsp_l, tokens_X.shape[0], 1)\n",
    "            timer.stop()\n",
    "            animator.add(step + 1,\n",
    "                         (metric[0] / metric[3], metric[1] / metric[3]))\n",
    "            step += 1\n",
    "            if step == num_steps:\n",
    "                num_steps_reached = True\n",
    "                break\n",
    "\n",
    "    print(f'MLM loss {metric[0] / metric[3]:.3f}, '\n",
    "          f'NSP loss {metric[1] / metric[3]:.3f}')\n",
    "    print(f'{metric[2] / timer.sum():.1f} sentence pairs/sec on '\n",
    "          f'{str(devices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d455ca1c-d1b7-4d14-a885-b971341755fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu(i=0):\n",
    "    \"\"\"Defined in :numref:`sec_use_gpu`\"\"\"\n",
    "    return torch.device(f'cuda:{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ec2ef1a-1325-4ae0-9e20-1c0f5f93132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_gpus():\n",
    "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\n",
    "    Defined in :numref:`sec_use_gpu`\"\"\"\n",
    "    return [gpu(i) for i in range(torch.cuda.device_count())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9582021f-1b94-498a-8b12-7106760bcfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = try_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7ace5a8-fd88-458f-bee1-ce3a0f2ed081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[device(type='cuda', index=0)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace458fc-5023-4819-8688-4ebc45eaa5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
